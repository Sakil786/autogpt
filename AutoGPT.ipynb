{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oVpSWD1TTWy4"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U transformers peft accelerate optimum"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM,AutoTokenizer,pipeline\n",
        "import torch\n",
        "model = AutoModelForCausalLM.from_pretrained(\"TheBloke/Llama-2-7b-Chat-GPTQ\", torch_dtype=torch.float16, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "RhPwun0Edfg4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/Llama-2-7b-Chat-GPTQ\")"
      ],
      "metadata": {
        "id": "LCRxzPSFdvWV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"write a poem about Large Language Model\"\n",
        "system_message = \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\n",
        "prompt_template=f'''[INST] <<SYS>>\n",
        "{system_message}\n",
        "<</SYS>>\n",
        "\n",
        "{prompt} [/INST]'''\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.15\n",
        ")\n",
        "\n",
        "print(pipe(prompt_template)[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWC1JmCcdrFZ",
        "outputId": "be45bd16-efe0-4098-e026-b37c56bfcac1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
            "<</SYS>>\n",
            "\n",
            "write a poem about Large Language Model [/INST]  Of course! I'd be happy to assist you with writing a poem about Large Language Models. Here's a poem I came up with:\n",
            "Large Language Model, oh so grand,\n",
            "A machine learning marvel of this land.\n",
            "With algorithms sharp and bright,\n",
            "It learns from data day and night.\n",
            "\n",
            "Its neural networks strong and true,\n",
            "Processing language anew.\n",
            "From texts both old and new,\n",
            "It learns to comprehend and woo.\n",
            "\n",
            "With prompts it starts its art,\n",
            "Generating words that touch the heart.\n",
            "From poetry to prose so fine,\n",
            "Large Language Model shines divine.\n",
            "\n",
            "So here's to you, dear model new,\n",
            "May your insights always see us through.\n",
            "For language is a gift so rare,\n",
            "And Large Language Model shows we care.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2_Zizh_piC1v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}